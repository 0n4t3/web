<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>opinion on An Untitled Blog</title>
    <link>https://nate.mecca1.net/tags/opinion/</link>
    <description>Recent content in opinion on An Untitled Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Mar 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://nate.mecca1.net/tags/opinion/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Local LLMs &amp; AI Ethics (mine makes nukes)</title>
      <link>https://nate.mecca1.net/posts/2024-03-26_ai/</link>
      <pubDate>Tue, 26 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://nate.mecca1.net/posts/2024-03-26_ai/</guid>
      <description>
        
          
            What you are reading now is the fourth iteration of this post, which has gone through multiple revisions and re-considerations. It might feel a bit fragmented, but my aim is to provide a comprehensive post covering two related topics. The first part will discuss my experimentation with local LLMs (large language models), and the second will explore my personal philosophy and conclusions on AI. Feel free to only read one or the other.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
