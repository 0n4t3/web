<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ai on An Untitled Blog</title>
    <link>/tags/ai/</link>
    <description>Recent content in ai on An Untitled Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 13 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Vibe Coding Chronicles</title>
      <link>/posts/2025-04-13_vibe-coding-chronicles/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>/posts/2025-04-13_vibe-coding-chronicles/</guid>
      <description>
        
          
            POV: You&amp;rsquo;re a professional dev watching me talk about vibe coding: Your browser does not support the video tag. I&amp;rsquo;m not exactly a stranger to using AI code, parts of nipy-bridge like the part that handles posts based on size was written by Chat GPT via Duck.AI, and I regularly use a Mixtral-Dolphin written bash script to convert files with avifenc. Recently, however, I came across Bookstr by MK Fain, which is being vibe coded.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Non-Generative uses of Local LLMs</title>
      <link>/posts/2024-10-15_non-generative-llm-uses/</link>
      <pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>/posts/2024-10-15_non-generative-llm-uses/</guid>
      <description>
        
          
            Update Oct. 21st: The transcription portion of the post has been updated, what I originally mistook as issues with how the data was formatted was an issue with too many tokens in the transcript I wanted transcribed.
At this point we all know how LLMs can generate text, and I&amp;rsquo;m guessing that everybody reading this knows some relatively lightweight libre LLMs can be installed and run locally. But, as you can probably guess by reading this, I enjoy writing stuff, so text generation isn&amp;rsquo;t really something that I have a use for.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Local LLMs and AI Ethics (mine makes nukes)</title>
      <link>/posts/2024-03-26_ai/</link>
      <pubDate>Tue, 26 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>/posts/2024-03-26_ai/</guid>
      <description>
        
          
            What you are reading now is the fourth iteration of this post, which has gone through multiple revisions and re-considerations. It might feel a bit fragmented, but my aim is to provide a comprehensive post covering two related topics. The first part will discuss my experimentation with local LLMs (large language models), and the second will explore my personal philosophy and conclusions on AI. Feel free to only read one or the other.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
