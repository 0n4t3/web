<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ai on An Untitled Blog</title>
    <link>https://nate.mecca1.net/tags/ai/</link>
    <description>Recent content in ai on An Untitled Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://nate.mecca1.net/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Non-Generative uses of Local LLMs</title>
      <link>https://nate.mecca1.net/posts/2024-10-15_non-generative-llm-uses/</link>
      <pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>https://nate.mecca1.net/posts/2024-10-15_non-generative-llm-uses/</guid>
      <description>
        
          
            At this point we all know how LLMs can generate text, and I&amp;rsquo;m guessing that everybody reading this knows some relatively lightweight libre LLMs can be installed and run locally. But, as you can probably guess by reading this, I enjoy writing stuff, so text generation isn&amp;rsquo;t really something that I have a use for. The knowledge stored in them is helpful for sure; I use local LLMs to find data or troubleshoot something on probably more or less a once-a-week basis (because I&amp;rsquo;m not connected to the internet, can&amp;rsquo;t find what I&amp;rsquo;m looking for in search engines, want to ask about an error code in plain English, etc).
          
          
        
      </description>
    </item>
    
    <item>
      <title>Local LLMs and AI Ethics (mine makes nukes)</title>
      <link>https://nate.mecca1.net/posts/2024-03-26_ai/</link>
      <pubDate>Tue, 26 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://nate.mecca1.net/posts/2024-03-26_ai/</guid>
      <description>
        
          
            What you are reading now is the fourth iteration of this post, which has gone through multiple revisions and re-considerations. It might feel a bit fragmented, but my aim is to provide a comprehensive post covering two related topics. The first part will discuss my experimentation with local LLMs (large language models), and the second will explore my personal philosophy and conclusions on AI. Feel free to only read one or the other.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
